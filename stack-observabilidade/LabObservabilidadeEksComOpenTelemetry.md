# ğŸ§ª Lab de Observabilidade com OpenTelemetry no EKS

Este repositÃ³rio Ã© um **exemplo completo e didÃ¡tico** para estudar observabilidade moderna usando **OpenTelemetry + Prometheus + Grafana + Tempo**, com foco prÃ¡tico em **SLIs, SLOs e alertas bem desenhados**.

---

## ğŸ“ Estrutura do RepositÃ³rio

```
observability-lab-eks/
â”œâ”€â”€ README.md
â”œâ”€â”€ eks/
â”‚   â””â”€â”€ cluster.yaml
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ otel/
â”‚   â””â”€â”€ otel-collector.yaml
â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ rules-slo.yaml
â”‚   â””â”€â”€ alerts.yaml
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”œâ”€â”€ app-red-metrics.json
â”‚   â”‚   â”œâ”€â”€ kubernetes-overview.json
â”‚   â”‚   â””â”€â”€ slo-overview.json
â”‚   â””â”€â”€ datasources.yaml
â””â”€â”€ helm-install.sh
```

---

## ğŸš€ AplicaÃ§Ã£o Exemplo (Python + Flask)

A aplicaÃ§Ã£o jÃ¡ nasce **instrumentada com OpenTelemetry**.

### app/app.py

```python
from flask import Flask
import random, time
from opentelemetry.instrumentation.flask import FlaskInstrumentor
from opentelemetry import trace

app = Flask(__name__)
FlaskInstrumentor().instrument_app(app)

@app.route("/")
def hello():
    time.sleep(random.uniform(0.1, 0.8))
    if random.random() < 0.1:
        return "error", 500
    return "hello world"

app.run(host="0.0.0.0", port=8080)
```

ğŸ‘‰ Essa app gera **latÃªncia variÃ¡vel, erros reais e traces distribuÃ­dos**.

---

## ğŸ”­ OpenTelemetry Collector (DaemonSet)

### otel/otel-collector.yaml

```yaml
mode: daemonset
receivers:
  otlp:
    protocols:
      grpc:
      http:
processors:
  batch: {}
exporters:
  prometheus:
    endpoint: "0.0.0.0:8889"
  otlp:
    endpoint: tempo.monitoring:4317
service:
  pipelines:
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheus]
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlp]
```

ğŸ“Œ **Ponto-chave**: aqui vocÃª controla sampling, enrich, fan-out.

---

## ğŸ“Š Dashboards Grafana (prontos)

### 1ï¸âƒ£ RED Metrics â€“ AplicaÃ§Ã£o

**Rate**

```promql
sum(rate(http_server_requests_total[5m]))
```

**Errors**

```promql
sum(rate(http_server_requests_total{status=~"5.."}[5m]))
```

**Duration (p95)**

```promql
histogram_quantile(0.95, rate(http_server_request_duration_seconds_bucket[5m]))
```

---

### 2ï¸âƒ£ Kubernetes Overview

* CPU por pod
* Memory por namespace
* Restarts
* LatÃªncia de API Server

---

### 3ï¸âƒ£ SLO Overview Dashboard

* Burn Rate (1h / 6h)
* Error Budget restante
* Disponibilidade mensal

---

## ğŸ¯ SLIs e SLOs (reais e usados em produÃ§Ã£o)

### ğŸ¯ SLI â€“ Disponibilidade

```promql
1 - (
  sum(rate(http_server_requests_total{status=~"5.."}[5m]))
  /
  sum(rate(http_server_requests_total[5m]))
)
```

### ğŸ¯ SLO

* **99.9% de sucesso em 30 dias**
* Error Budget: **0.1%**

---

### ğŸ”¥ Burn Rate

```promql
(
  sum(rate(http_server_requests_total{status=~"5.."}[5m]))
  /
  sum(rate(http_server_requests_total[5m]))
) / 0.001
```

---

## ğŸš¨ Alertas bem feitos (sem ruÃ­do)

### ğŸš¨ Alert: SLO Burn Rate Alto (rÃ¡pido)

```yaml
groups:
- name: slo-alerts
  rules:
  - alert: HighBurnRate
    expr: slo_burn_rate_5m > 14
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "SLO queimando rÃ¡pido"
```

### ğŸš¨ Alert: Erro Sustentado

```yaml
- alert: HighErrorRate
  expr: |
    sum(rate(http_server_requests_total{status=~"5.."}[10m]))
    /
    sum(rate(http_server_requests_total[10m])) > 0.02
  for: 10m
  labels:
    severity: warning
```

ğŸ“Œ **Por que isso Ã© bom?**

* Janela de tempo
* Baseado em impacto real
* Pouco ruÃ­do

---

## ğŸ§  O que vocÃª aprende com esse lab

âœ” OpenTelemetry de verdade (SDK + Collector)
âœ” MÃ©tricas Kubernetes + app
âœ” Tracing distribuÃ­do
âœ” SLIs / SLOs acionÃ¡veis
âœ” Alertas orientados a erro de usuÃ¡rio

---

## ğŸ§­ PrÃ³ximos upgrades

* Adicionar Loki (logs correlacionados)
* Adicionar exemplars (trace_id nas mÃ©tricas)
* Canary + SLO por versÃ£o
* Chaos Engineering

---

## âœ… ConclusÃ£o

Este repo simula **exatamente o que empresas maduras usam**.

Se vocÃª domina isso, vocÃª:

* Entende produÃ§Ã£o
* Reduz MTTR
* Cria alertas confiÃ¡veis

ğŸ‘‰ PrÃ³ximo passo possÃ­vel: **Datadog vs OpenTelemetry**, **SLO multi-tenant**, ou **Golden Signals em larga escala**.
