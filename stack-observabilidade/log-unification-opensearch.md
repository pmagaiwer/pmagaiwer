# Arquitetura de Log Unification Multi-Account com OpenSearch e Delay Controlado

Arquitetura clÃ¡ssica para centralizaÃ§Ã£o de logs em ambientes multi-conta AWS, usando OpenSearch como motor de busca e delay proposital (~15 minutos) para otimizar custo, estabilidade e seguranÃ§a.

---

## ğŸ¯ Objetivo da arquitetura
- Centralizar logs de vÃ¡rias contas AWS
- Normalizar, enriquecer e controlar volume
- Disponibilizar consulta no OpenSearch
- Aceitar latÃªncia de ~15 minutos para:
  - Reduzir custo
  - Evitar picos
  - Garantir confiabilidade

---

## ğŸ” Fluxo completo (fim a fim)

### 1ï¸âƒ£ ProduÃ§Ã£o dos logs (Contas A, B, C)
- EKS: logs de aplicaÃ§Ãµes e containers
- EC2
- Outros serviÃ§os AWS
- **Coleta:** Fluent Bit (DaemonSet no EKS ou agente em EC2)
- **Status:** logs ainda crus (raw logs)

### 2ï¸âƒ£ Agentes de coleta (Fluent Bit)
- LÃª stdout/stderr de containers, arquivos de log, systemd/journald
- Enriquecimento: cluster, namespace, pod, account_id
- Envia logs via HTTP / Firehose / Kinesis
- **Agente leve, sem processamento pesado**

### 3ï¸âƒ£ Buffer + desacoplamento (onde nasce o delay)
- Logs passam por Kinesis Data Streams ou Kinesis Firehose
- **FunÃ§Ã£o:**
  - Absorver picos
  - Evitar sobrecarga no OpenSearch
  - Permitir flush controlado (ex: a cada 5, 10 ou 15 minutos)
- **Aqui comeÃ§a a latÃªncia proposital**

### 4ï¸âƒ£ Camada de processamento central
- EC2 / Auto Scaling Group rodando Fluentd, Logstash ou pipeline customizado
- **FunÃ§Ãµes:**
  - Parse (JSON, regex, grok)
  - NormalizaÃ§Ã£o
  - Enriquecimento (app, domÃ­nio, squad)
  - Drop de logs inÃºteis
  - Redirecionamento por tipo
- **Buffer em memÃ³ria + disco**
- **Buffer + batch + flush = ~15 minutos**

### 5ï¸âƒ£ PersistÃªncia intermediÃ¡ria (opcional)
- Logs podem ser salvos em S3 (raw ou parquet) antes do OpenSearch
- **BenefÃ­cios:** replay, compliance, disaster recovery

### 6ï¸âƒ£ IndexaÃ§Ã£o no OpenSearch
- ApÃ³s batch completo, pipeline OK e backpressure resolvido
- Envio para Amazon OpenSearch Service
- Ãndices organizados por data, tipo de log, aplicaÃ§Ã£o
- **IndexaÃ§Ã£o em lote = melhor performance e custo**

### 7ï¸âƒ£ VisualizaÃ§Ã£o e acesso
- Dashboards do OpenSearch
- Controle de acesso: Okta, IAM, RBAC
- UsuÃ¡rios: SRE, SecOps, Engenharia, Auditoria

---

## â±ï¸ Por que exatamente 15 minutos de delay?
- **Motivos tÃ©cnicos:**
  - Flush de batch (5â€“10 min)
  - Buffer de seguranÃ§a
  - Retry em falha
  - Controle de throughput
- **Motivos financeiros:**
  - Menos shards ativos
  - Menos write IOPS
  - Menos custo no OpenSearch
- **Motivos operacionais:**
  - Evita perder logs em pico
  - Evita travar cluster
  - Logs chegam completos e consistentes

> Para observabilidade operacional, 15 min Ã© aceitÃ¡vel
> Para seguranÃ§a e auditoria, Ã© atÃ© recomendado

---

## ğŸ” Quando isso NÃƒO Ã© ideal?
- Debug em tempo real
- Incident response imediato
- APM / tracing

**Nestes casos:**
- Logs crÃ­ticos podem ir direto para OpenSearch
- Ou para CloudWatch Logs / Datadog
- Com pipeline paralelo (low latency)

---

## ğŸ§  Resumo mental simples
```
AplicaÃ§Ã£o
  â†“
Fluent Bit
  â†“
Kinesis / Firehose (buffer)
  â†“
Processamento central (batch)
  â†“
(Opcional) S3
  â†“
OpenSearch
  â†“
Dashboards (15 min depois)
```

---

## ğŸ¯ Em uma frase

Essa arquitetura prioriza escala, custo e confiabilidade, aceitando latÃªncia controlada (~15 minutos) para garantir que os logs cheguem completos, organizados e sem derrubar o OpenSearch.
